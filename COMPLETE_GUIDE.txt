═══════════════════════════════════════════════════════════════════════════════
                  DRONE TRACKING SYSTEM - COMPLETE GUIDE
═══════════════════════════════════════════════════════════════════════════════

WHAT YOU HAVE:
══════════════
1. YOLOv8n AI Model - Detects objects in video (drones, birds, cars, etc.)
2. Kalman Filter - Smooths drone movement and predicts next position
3. Hungarian Algorithm - Matches detections across frames to track drones

═══════════════════════════════════════════════════════════════════════════════

PART 1: VIRTUAL ENVIRONMENT (THE DRONE39 ENVIRONMENT)
═══════════════════════════════════════════════════════

What is it?
──────────
A separate Python installation with all the packages your project needs:
- PyTorch 2.8.0 (deep learning)
- OpenCV (video processing)
- ultralytics (YOLOv8)
- filterpy (Kalman filter)
- NumPy, SciPy (math)

Location: C:\Users\chipn\Miniconda3\envs\drone39
Name:     drone39
Python:   3.9.25

Why Do You Need It?
───────────────────
Each package has different requirements:
- YOLOv8 needs PyTorch 2.8
- OpenCV needs specific codecs
- Kalman filter needs NumPy 2.0+
- Virtual environment keeps all compatible versions together

How to Activate:
────────────────
Option 1 (Automatic): Double-click "run_tracker.ps1" - it activates automatically

Option 2 (Manual): Open PowerShell and type:
  C:\Users\chipn\Miniconda3\Scripts\conda.exe activate drone39

Option 3 (Command): Use full path in commands (see Part 2)

═══════════════════════════════════════════════════════════════════════════════

PART 2: HOW TO RUN THE TRACKER (EVERY TIME)
═════════════════════════════════════════════

EASIEST METHOD: Double-click run_tracker.ps1
───────────────────────────────────────────
1. Place your video files in: e:\kshatra\drone-tracker\videos\
2. Double-click: e:\kshatra\drone-tracker\run_tracker.ps1
3. Wait for "SUCCESS!" message
4. Check outputs in: e:\kshatra\drone-tracker\outputs\

COMMAND LINE METHOD (PowerShell):
─────────────────────────────────
$conda = "C:\Users\chipn\Miniconda3\Scripts\conda.exe"
Set-Location 'e:\kshatra\drone-tracker'
& $conda run -n drone39 python -m src.main --input-dir videos --output-dir outputs --conf 0.15 --scale 0.6

JUPYTER NOTEBOOK METHOD:
────────────────────────
Run: DRONE_TRACKING_EXPLAINED.ipynb
Just execute the cells and watch results appear

═══════════════════════════════════════════════════════════════════════════════

PART 3: THE TRACKING ALGORITHM (SIMPLIFIED)
════════════════════════════════════════════

Step 1: YOLO DETECTS EVERYTHING
────────────────────────────────
Frame → [YOLO Model] → All objects detected
                    → (drones, birds, insects, etc.)
                    → Each with confidence score (0-1)

Step 2: FILTER TO DRONES ONLY
──────────────────────────────
All Detections → [Check class type]
              → [Check size (not tiny, not huge)]
              → [Check confidence > 0.15]
              → Only Drones Pass ✓

Step 3: MATCH ACROSS FRAMES
────────────────────────────
Current Frame:     Previous Frame Tracks:
Detections:        [Track 1] [Track 2] [Track 3]
[D1] [D2]              ↓
                  Which detection matches which track?
[Hungarian Algorithm calculates IoU overlap]
Result: D1 → Track 1 (same drone)
        D2 → New Track 4 (new drone)

Step 4: KALMAN FILTER (SMOOTHING)
──────────────────────────────────
Raw Detection:     x=150, y=200 (noisy, jiggly)
                   ↓
Kalman Filter:     Predicts motion based on velocity
                   Removes noise
                   ↓
Smoothed Output:   x=151, y=202 (smooth, stable)

State Vector (7D):
[cx, cy, scale, aspect_ratio, vx, vy, v_scale]
 Position Position  Size   Shape      Velocities (motion)

Step 5: OUTPUT
──────────────
Frame 1: Drone ID=1 at box (150, 200, 300, 350)
Frame 2: Drone ID=1 at box (155, 205, 305, 355) ← SAME ID (tracking!)
Frame 3: Drone ID=1 at box (160, 210, 310, 360) ← SAME ID (tracking!)

═══════════════════════════════════════════════════════════════════════════════

PART 4: UNDERSTANDING ID NUMBERS
═════════════════════════════════

What is an ID?
──────────────
A unique number (1, 2, 3, ...) assigned to each drone for tracking.

Example Video with 2 Drones:
────────────────────────────
Frame 1-50:    ID=1 detected (first drone appears)
Frame 51-100:  ID=1 still there + ID=2 appears (second drone)
Frame 101-150: ID=1 gone, ID=2 still there
Frame 151+:    ID=2 gone

CSV Output:
───────────
frame,id,x1,y1,x2,y2
1,1,150,200,300,350
2,1,155,205,305,355
3,1,160,210,310,360
51,1,400,100,550,250
51,2,50,50,150,150
52,1,410,110,560,260
52,2,60,60,160,160
...

Why So Many Rows?
─────────────────
Video = 30 FPS × 100 seconds = 3000 frames
If 2 drones per frame = 6000 rows total
This is NORMAL! One row per detection per frame.

═══════════════════════════════════════════════════════════════════════════════

PART 5: THE CSV FILE (TRACKING DATA)
═════════════════════════════════════

What is it?
───────────
A spreadsheet file with drone positions in every frame.

Columns:
────────
| Column | Meaning | Example |
|--------|---------|---------|
| frame  | Frame number (1, 2, 3, ...) | 1 |
| id     | Drone ID (same = same drone) | 1 |
| x1     | Left edge of bounding box | 150 |
| y1     | Top edge of bounding box | 200 |
| x2     | Right edge of bounding box | 300 |
| y2     | Bottom edge of bounding box | 350 |

Understanding the Box:
──────────────────────
     (x1,y1)
        ┌─────────┐
        │ DRONE   │ Box width = x2-x1 = 300-150 = 150 px
        │         │ Box height = y2-y1 = 350-200 = 150 px
        └─────────┘
              (x2,y2)

How to Use:
───────────
1. Open: e:\kshatra\drone-tracker\outputs\tracked_*.csv
2. In Excel: Filter by ID=1
3. See all positions of drone 1 across frames
4. Plot (x1+x2)/2 vs frame = drone path

═══════════════════════════════════════════════════════════════════════════════

PART 6: PARAMETERS EXPLAINED
═════════════════════════════

--conf 0.15 (Confidence threshold)
────────────────────────────────────
- Range: 0.0 to 1.0
- Lower (0.05) = More detections (slower, more false positives)
- Higher (0.50) = Fewer detections (faster, fewer drones detected)
- Default: 0.15 (good balance)

--scale 0.6 (Output resolution scaling)
────────────────────────────────────────
- Range: 0.3 to 1.0
- 1.0 = Full resolution (large files, slow)
- 0.6 = 60% resolution (3x faster, smaller files)
- 0.3 = 30% resolution (10x faster, tiny files)
- Default: 0.6 (good for testing)

--max-age 60 (Track persistence)
─────────────────────────────────
- How long to keep a track if not detected
- Higher = tolerates brief occlusions
- Default: 60 frames (~2 seconds at 30 FPS)

--iou-threshold 0.25 (Matching threshold)
───────────────────────────────────────────
- How much overlap needed to match detection to track
- Lower = easier to match (but may match wrong drones)
- Higher = stricter matching
- Default: 0.25

═══════════════════════════════════════════════════════════════════════════════

PART 7: WHY DETECTION FILTERS?
═══════════════════════════════

Problem: YOLO Detects Everything
──────────────────────────────────
Frame → [YOLO] → Detections:
                - ID=1: Bird (class=14)
                - ID=2: Drone ← You want this
                - ID=3: Dust (class=54)
                - ID=4: Drone ← You want this
                - ID=5: Insect

Result: CSV full of random IDs ✗

Solution: Filter by Class + Size
───────────────────────────────
Frame → [YOLO] → All Detections
            ↓
       [Check if NOT person/car/bike/etc.]
       [Check if size 100-50000 px²]
       [Check if confidence > 0.15]
            ↓
           Drones Only ✓

Result: CSV has clean drone IDs ✓

Excluded Classes:
─────────────────
0=person, 1=bicycle, 2=car, 3=motorbike, 5=bus, 7=truck, 8=boat, etc.
(These are NOT drones, so we skip them)

═══════════════════════════════════════════════════════════════════════════════

PART 8: FOLDER STRUCTURE
═════════════════════════

e:\kshatra\drone-tracker\
├── src\
│   ├── main.py ........................... Entry point (runs everything)
│   ├── tracker.py ........................ Tracks drones across frames
│   ├── kalman_filter.py ................. Smooths drone motion
│   ├── utils.py ......................... Helper functions
│   └── __init__.py
├── videos\ ............................. YOUR VIDEO FILES GO HERE
│   ├── Quality_Chase_footage.mp4
│   ├── cropped_Quality_Chase_footage.mp4
│   └── videoplayback.mp4
├── outputs\ ............................ RESULTS APPEAR HERE
│   ├── tracked_*.mp4 ................... Video with green boxes
│   └── tracked_*.csv ................... Tracking data
├── models\ ............................. AI models
│   └── yolov8n.pt ...................... YOLOv8 weights (6.5 MB)
├── run_tracker.ps1 ..................... DOUBLE-CLICK TO RUN
├── DRONE_TRACKING_EXPLAINED.ipynb ....... Notebook with code & examples
├── README.md ........................... Full documentation
└── requirements.txt ..................... Python packages

═══════════════════════════════════════════════════════════════════════════════

PART 9: QUICK START
════════════════════

1. Add Videos
   - Copy your drone videos to: e:\kshatra\drone-tracker\videos\
   - Supported formats: .mp4, .avi, .mov, .mkv

2. Run Tracker (Choose One Method)

   METHOD A (Easiest - Double-click):
   - Navigate to: e:\kshatra\drone-tracker\
   - Double-click: run_tracker.ps1
   - Wait for "SUCCESS!" message

   METHOD B (PowerShell):
   - Open PowerShell
   - Copy: $conda = "C:\Users\chipn\Miniconda3\Scripts\conda.exe"; Set-Location 'e:\kshatra\drone-tracker'; & $conda run -n drone39 python -m src.main --input-dir videos --output-dir outputs --conf 0.15 --scale 0.6
   - Press Enter
   - Wait 3-5 minutes

   METHOD C (Jupyter Notebook):
   - Open: DRONE_TRACKING_EXPLAINED.ipynb
   - Run cells 5-6
   - Watch results appear

3. View Results
   - Videos: e:\kshatra\drone-tracker\outputs\tracked_*.mp4 (open with VLC)
   - Data: e:\kshatra\drone-tracker\outputs\tracked_*.csv (open with Excel)

4. Verify Tracking
   - Green boxes = Detected drones ✓
   - ID numbers = Track IDs (same ID = same drone)
   - Smooth motion = Kalman filter working ✓

═══════════════════════════════════════════════════════════════════════════════

PART 10: TROUBLESHOOTING
═════════════════════════

Problem: "conda not found" or "Python not found"
─────────────────────────────────────────────────
Solution: Use the full path in run_tracker.ps1 (already done)

Problem: "ModuleNotFoundError: ultralytics"
────────────────────────────────────────────
Solution: You're not in drone39 environment
  → Use run_tracker.ps1 (it activates automatically)

Problem: Output video is SHORT / MISSING
──────────────────────────────────────────
Solution: Disk was full (we fixed this with --scale 0.6)
  → 0.6 = 60% resolution = much smaller files
  → Try --scale 0.3 if still too large

Problem: No GREEN BOXES in output video
─────────────────────────────────────────
Solution: Lower confidence threshold
  → Change --conf 0.15 to --conf 0.10

Problem: Too many non-drone detections
───────────────────────────────────────
Solution: This is filtering working (excluding large objects)
  → Expected behavior
  → Notebook shows how it filters

Problem: Processing is SLOW
───────────────────────────
Solution: 1. Reduce resolution (--scale 0.3)
         2. Lower FPS (modify main.py line ~80)
         3. Use GPU (if NVIDIA card available)

═══════════════════════════════════════════════════════════════════════════════

FREQUENTLY ASKED QUESTIONS
═════════════════════════════

Q: Why do I need a virtual environment?
A: Different packages have version conflicts. Virtual env isolates them.

Q: Can I just use system Python?
A: No. It's likely Python 3.12, but YOLOv8 needs 3.9.

Q: How do I add MORE videos?
A: Put .mp4 files in videos\ folder, run tracker again.

Q: Can I use a GPU?
A: Yes! If you have NVIDIA GPU:
   - Reinstall PyTorch with CUDA
   - Performance: ~50 FPS instead of 10 FPS

Q: Why does the output video have "random" green boxes?
A: The filtering is catching non-drones. This is normal.
   To improve: Lower confidence threshold (--conf 0.10)

Q: What's the difference between --scale 0.6 and --scale 1.0?
A: 0.6 = 60% size (3x faster, smaller file)
   1.0 = 100% size (slow, large file)

Q: Can I track specific drone models?
A: Yes! Train a custom YOLO model on your drone type.
   For now, the filter works on size + class.

═══════════════════════════════════════════════════════════════════════════════

CONTACT / SUPPORT
══════════════════
Files:
- Main code: e:\kshatra\drone-tracker\src\main.py
- Tracker logic: e:\kshatra\drone-tracker\src\tracker.py
- Kalman filter: e:\kshatra\drone-tracker\src\kalman_filter.py
- Full notebook: DRONE_TRACKING_EXPLAINED.ipynb

═══════════════════════════════════════════════════════════════════════════════
