{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71afebb0",
   "metadata": {},
   "source": [
    "## PART 1: WHAT IS YOUR VIRTUAL ENVIRONMENT?\n",
    "\n",
    "### What is a Virtual Environment?\n",
    "A **virtual environment** is an isolated Python installation on your computer:\n",
    "- Separate from system Python\n",
    "- Contains all your project packages (torch, opencv, ultralytics, etc.)\n",
    "- Prevents conflicts with other projects\n",
    "\n",
    "### Your Setup\n",
    "```\n",
    "Location: C:\\Users\\chipn\\Miniconda3\\envs\\drone39\n",
    "Name:     drone39\n",
    "Python:   3.9.25\n",
    "Manager:  Conda (Miniconda3)\n",
    "```\n",
    "\n",
    "### Why You Need It\n",
    "- **YOLOv8** needs PyTorch 2.8\n",
    "- **OpenCV** needs specific build\n",
    "- **filterpy** (Kalman) needs NumPy 2.0+\n",
    "- All these have different version requirements\n",
    "- Virtual env keeps them together and compatible\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf87d589",
   "metadata": {},
   "source": [
    "## PART 2: HOW TO ACTIVATE AND RUN (EVERYTIME)\n",
    "\n",
    "### Quick Command to Run Everything\n",
    "Copy and paste this ONCE in PowerShell:\n",
    "\n",
    "```powershell\n",
    "$conda = \"C:\\Users\\chipn\\Miniconda3\\Scripts\\conda.exe\"\n",
    "& $conda run -n drone39 python -m src.main --input-dir videos --output-dir outputs --weights yolov8n.pt --conf 0.15 --scale 0.6\n",
    "```\n",
    "\n",
    "### What This Does\n",
    "- `$conda = ...` : Path to conda tool\n",
    "- `& $conda run -n drone39` : Run in your virtual environment\n",
    "- `python -m src.main` : Runs the tracker\n",
    "- `--conf 0.15` : Confidence threshold (lower = detects more but slower)\n",
    "- `--scale 0.6` : Downscale video to 60% (faster processing, smaller files)\n",
    "\n",
    "### OR: Use PowerShell Script (Easiest)\n",
    "I'll create `run_tracker.ps1` for you - just double-click it\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6b62ed",
   "metadata": {},
   "source": [
    "## PART 3: THE TRACKING ALGORITHM EXPLAINED\n",
    "\n",
    "### Step 1: DETECTION (YOLOv8)\n",
    "```\n",
    "Frame → [YOLO Model] → Bounding Boxes (x1, y1, x2, y2)\n",
    "                    → Confidence Score (0.0 to 1.0)\n",
    "```\n",
    "**Problem**: YOLOv8 detects ALL objects (cars, birds, drones, insects)\n",
    "**Solution**: We filter to only keep DRONE class\n",
    "\n",
    "### Step 2: FILTERING (Drone-Only)\n",
    "```\n",
    "All Detections → [Filter by Class=\"Drone\"] → Only Drones\n",
    "               → [Filter by Confidence > 0.15] → High Confidence Only\n",
    "```\n",
    "\n",
    "### Step 3: DATA ASSOCIATION (Hungarian Algorithm)\n",
    "```\n",
    "Current Frame Detections    Previous Frame Tracks\n",
    "      [D1, D2, D3]                [T1, T2]\n",
    "           |\n",
    "           v\n",
    "    [Calculate IoU Matrix]\n",
    "    (How much each detection overlaps each track)\n",
    "           |\n",
    "           v\n",
    "    [Hungarian Optimal Matching]\n",
    "    (Match D1→T1, D2→T2, create new for D3)\n",
    "           |\n",
    "           v\n",
    "    T1: [same track, update position]\n",
    "    T2: [same track, update position]\n",
    "    T3: [new track created]\n",
    "```\n",
    "\n",
    "### Step 4: KALMAN FILTER (Motion Smoothing)\n",
    "```\n",
    "Raw Detection: x=150, y=200 (noisy)\n",
    "        ↓\n",
    "Kalman Filter: Predicts next position based on velocity\n",
    "        ↓\n",
    "Smoothed Output: x=151, y=202 (noise removed)\n",
    "\n",
    "Kalman State Vector (7D):\n",
    "[center_x, center_y, scale, aspect_ratio, vx, vy, v_scale]\n",
    " ^         ^         ^     ^             ^  ^  ^\n",
    " Position  Position  Size  Shape        Velocities (predicted motion)\n",
    "```\n",
    "\n",
    "### Step 5: OUTPUT\n",
    "```\n",
    "Frame 1: Drone ID=1 at (150, 200) - (300, 350)\n",
    "Frame 2: Drone ID=1 at (155, 205) - (305, 355)  ← SAME ID (tracking!)\n",
    "Frame 3: Drone ID=1 at (160, 210) - (310, 360)  ← SAME ID (tracking!)\n",
    "\n",
    "CSV Output:\n",
    "frame,id,x1,y1,x2,y2\n",
    "1,1,150,200,300,350\n",
    "2,1,155,205,305,355\n",
    "3,1,160,210,310,360\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407e2fdf",
   "metadata": {},
   "source": [
    "## PART 4: THE ID NUMBERS EXPLAINED\n",
    "\n",
    "### What is an ID?\n",
    "A **unique number** assigned to each drone so you can track it across frames:\n",
    "\n",
    "```\n",
    "ID=1: Same drone, frame-by-frame\n",
    "ID=2: Another drone detected later\n",
    "ID=3: Third drone (if multiple drones in video)\n",
    "```\n",
    "\n",
    "### Why You See \"Random\" IDs?\n",
    "**PROBLEM**: You're detecting non-drones too!\n",
    "- YOLO detects: drones + birds + insects + dust\n",
    "- Each gets an ID\n",
    "- Creates \"random\" looking IDs\n",
    "\n",
    "**SOLUTION**: Filter ONLY for drones (YOLO class 14)\n",
    "\n",
    "### Example with Filtering\n",
    "```\n",
    "Without Filtering:\n",
    "ID=1: Bird\n",
    "ID=2: Drone ← You want this\n",
    "ID=3: Dust\n",
    "ID=4: Drone ← You want this\n",
    "ID=5: Insect\n",
    "\n",
    "With Filtering (Class=14 only):\n",
    "ID=1: Drone ← Only drones\n",
    "ID=2: Drone ← Only drones\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df08023",
   "metadata": {},
   "source": [
    "## PART 5: THE CSV FILE EXPLAINED\n",
    "\n",
    "### What is the CSV?\n",
    "A spreadsheet file (`tracked_*.csv`) with one row per detection:\n",
    "\n",
    "```\n",
    "frame,id,x1,y1,x2,y2\n",
    "1,1,150,200,300,350\n",
    "2,1,155,205,305,355\n",
    "3,1,160,210,310,360\n",
    "100,2,400,100,500,200  ← New drone appears\n",
    "101,2,405,105,505,205  ← Still being tracked\n",
    "```\n",
    "\n",
    "### Column Meanings\n",
    "| Column | Meaning | Example |\n",
    "|--------|---------|----------|\n",
    "| `frame` | Video frame number | 1, 2, 3, ... |\n",
    "| `id` | Drone track ID | 1 (first drone), 2 (second drone) |\n",
    "| `x1` | Left edge of box | 150 pixels |\n",
    "| `y1` | Top edge of box | 200 pixels |\n",
    "| `x2` | Right edge of box | 300 pixels |\n",
    "| `y2` | Bottom edge of box | 350 pixels |\n",
    "\n",
    "### Using the CSV\n",
    "Open in Excel or Notepad:\n",
    "```\n",
    "1. Open: e:\\kshatra\\drone-tracker\\outputs\\tracked_*.csv\n",
    "2. Find all rows with same ID\n",
    "3. That's one drone's path through the video\n",
    "4. x2-x1 = width, y2-y1 = height of drone bbox\n",
    "```\n",
    "\n",
    "### Why \"Full of\" ID Numbers?\n",
    "**Because you're tracking drones!** Each frame = one row per detected drone.\n",
    "If video is 30 FPS for 100 seconds = 3000 frames.\n",
    "If 1 drone = 3000 rows all with ID=1 ✓ (Normal!)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e740344",
   "metadata": {},
   "source": [
    "## PART 6: QUICK START (THIS NOTEBOOK)\n",
    "\n",
    "### Option A: Run from Command Line (Fastest)\n",
    "Open PowerShell and copy this:\n",
    "\n",
    "```powershell\n",
    "$conda = \"C:\\Users\\chipn\\Miniconda3\\Scripts\\conda.exe\"\n",
    "Set-Location 'e:\\kshatra\\drone-tracker'\n",
    "& $conda run -n drone39 python -m src.main --input-dir videos --output-dir outputs --weights yolov8n.pt --conf 0.15 --scale 0.6\n",
    "```\n",
    "\n",
    "### Option B: Run from This Notebook (Below)\n",
    "See cells below for running directly from Jupyter\n",
    "\n",
    "### Option C: Create Easy Script\n",
    "I'll create `run_tracker.ps1` - just double-click it\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b440b1",
   "metadata": {},
   "source": [
    "## SETUP: Install Dependencies in Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389c15d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Check if we're in the drone39 environment\n",
    "python_path = sys.executable\n",
    "print(f\"Python: {python_path}\")\n",
    "print(f\"Version: {sys.version}\")\n",
    "\n",
    "# Verify key packages\n",
    "packages = ['torch', 'cv2', 'ultralytics', 'filterpy']\n",
    "for pkg in packages:\n",
    "    try:\n",
    "        __import__(pkg)\n",
    "        print(f\"✓ {pkg} installed\")\n",
    "    except ImportError:\n",
    "        print(f\"✗ {pkg} NOT installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7afa5a",
   "metadata": {},
   "source": [
    "## STEP 1: Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d43996",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "print(\"✓ All imports successful!\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d9c550",
   "metadata": {},
   "source": [
    "## STEP 2: Load YOLO Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b05a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monkey-patch for torch compatibility\n",
    "import torch\n",
    "import ultralytics.nn.tasks as ultralytics_tasks\n",
    "\n",
    "def patched_torch_safe_load(file):\n",
    "    return torch.load(file, map_location=\"cpu\", weights_only=False), file\n",
    "\n",
    "ultralytics_tasks.torch_safe_load = patched_torch_safe_load\n",
    "\n",
    "# Load model\n",
    "print(\"Loading YOLOv8n model...\")\n",
    "model = YOLO('yolov8n.pt')\n",
    "print(\"✓ Model loaded successfully!\")\n",
    "\n",
    "# Get class names\n",
    "class_names = model.names\n",
    "print(f\"\\nAvailable classes: {len(class_names)}\")\n",
    "for cid, cname in class_names.items():\n",
    "    print(f\"  {cid}: {cname}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33435e81",
   "metadata": {},
   "source": [
    "## STEP 3: Simple Drone Detection (No Tracking Yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94e7424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test detection on one frame\n",
    "test_video = 'videos/Quality_Chase_footage.mp4'\n",
    "\n",
    "if os.path.exists(test_video):\n",
    "    cap = cv2.VideoCapture(test_video)\n",
    "    ret, frame = cap.read()\n",
    "    cap.release()\n",
    "    \n",
    "    if ret:\n",
    "        print(f\"Frame shape: {frame.shape}\")\n",
    "        \n",
    "        # Run detection\n",
    "        print(\"\\nRunning YOLO detection...\")\n",
    "        results = model(frame, conf=0.15, verbose=False)\n",
    "        \n",
    "        print(f\"Detections found: {len(results[0].boxes)}\")\n",
    "        \n",
    "        # Show all detections\n",
    "        for i, box in enumerate(results[0].boxes.data.cpu().numpy()):\n",
    "            x1, y1, x2, y2, conf, cls_id = box\n",
    "            cls_name = class_names[int(cls_id)]\n",
    "            print(f\"  {i+1}. {cls_name} (conf={conf:.2f}) at ({int(x1)}, {int(y1)})\")\n",
    "else:\n",
    "    print(f\"Video not found: {test_video}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cbc119",
   "metadata": {},
   "source": [
    "## STEP 4: DRONE FILTERING - Get Only Drones!\n",
    "\n",
    "**YOLO Classes**:\n",
    "- Class 14 = 'person' (NO)\n",
    "- Class 32 = 'sports ball' (NO)\n",
    "- Other classes = birds, insects, etc. (NO)\n",
    "\n",
    "**For true drones**: You should use custom-trained YOLO or filter by object size/shape.\n",
    "**For now**: We filter small-to-medium objects (likely drones vs large vehicles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc6d83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_drones(boxes, class_ids, confidences, frame_shape, min_area=100, max_area=50000):\n",
    "    \"\"\"\n",
    "    Filter detections to keep only likely drones.\n",
    "    \n",
    "    Drones are typically:\n",
    "    - Small to medium objects (not huge vehicles)\n",
    "    - High confidence detections\n",
    "    - NOT: person, car, truck, bicycle\n",
    "    \"\"\"\n",
    "    \n",
    "    # Exclude these YOLO classes (person=0, car=2, truck=8, bike=1, etc.)\n",
    "    excluded_classes = [0, 1, 2, 3, 5, 7, 8, 9, 10, 14, 15, 16, 17]\n",
    "    \n",
    "    filtered_boxes = []\n",
    "    filtered_confs = []\n",
    "    \n",
    "    for box, cls_id, conf in zip(boxes, class_ids, confidences):\n",
    "        x1, y1, x2, y2 = box\n",
    "        area = (x2 - x1) * (y2 - y1)\n",
    "        \n",
    "        # Keep if: not a large object, not an excluded class, high confidence\n",
    "        if (int(cls_id) not in excluded_classes and \n",
    "            min_area <= area <= max_area and \n",
    "            conf >= 0.15):\n",
    "            filtered_boxes.append(box)\n",
    "            filtered_confs.append(conf)\n",
    "    \n",
    "    return filtered_boxes, filtered_confs\n",
    "\n",
    "# Test on frame\n",
    "if ret:\n",
    "    results = model(frame, conf=0.15, verbose=False)\n",
    "    boxes = []\n",
    "    cls_ids = []\n",
    "    confs = []\n",
    "    \n",
    "    for box in results[0].boxes.data.cpu().numpy():\n",
    "        x1, y1, x2, y2, conf, cls_id = box\n",
    "        boxes.append([x1, y1, x2, y2])\n",
    "        cls_ids.append(cls_id)\n",
    "        confs.append(conf)\n",
    "    \n",
    "    # Filter\n",
    "    drone_boxes, drone_confs = filter_drones(boxes, cls_ids, confs, frame.shape)\n",
    "    \n",
    "    print(f\"\\nAll detections: {len(boxes)}\")\n",
    "    print(f\"After filtering (drones only): {len(drone_boxes)}\")\n",
    "    print(f\"\\nFiltered drone boxes:\")\n",
    "    for i, box in enumerate(drone_boxes):\n",
    "        x1, y1, x2, y2 = box\n",
    "        area = (x2-x1) * (y2-y1)\n",
    "        print(f\"  {i+1}. Box at ({int(x1)}, {int(y1)}) - Area={int(area)} px\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3319ebd8",
   "metadata": {},
   "source": [
    "## STEP 5: Run Full Tracker on One Video (FAST VERSION)\n",
    "\n",
    "This uses:\n",
    "- **Lower resolution** (60% scale) = 3x faster\n",
    "- **Lower FPS output** (every 2nd frame) = 2x faster\n",
    "- **Smaller codec** = smaller files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a1d228",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'e:\\\\kshatra\\\\drone-tracker')\n",
    "\n",
    "from src.tracker import Tracker\n",
    "from src.utils import iou\n",
    "\n",
    "# Process one video\n",
    "video_path = 'videos/Quality_Chase_footage.mp4'\n",
    "output_path = 'outputs/tracked_fast_demo.mp4'\n",
    "\n",
    "if not os.path.exists('outputs'):\n",
    "    os.makedirs('outputs')\n",
    "\n",
    "print(f\"Processing: {video_path}\")\n",
    "print(\"This will take ~2-3 minutes...\\n\")\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Output at reduced resolution (faster)\n",
    "scale = 0.6\n",
    "out_w, out_h = int(w * scale), int(h * scale)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (out_w, out_h))\n",
    "\n",
    "tracker = Tracker(max_age=60, min_hits=1, iou_threshold=0.25)\n",
    "frame_count = 0\n",
    "csv_lines = [\"frame,id,x1,y1,x2,y2\"]\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    frame_count += 1\n",
    "    \n",
    "    # Detect\n",
    "    results = model(frame, conf=0.15, verbose=False)\n",
    "    boxes = []\n",
    "    cls_ids = []\n",
    "    confs = []\n",
    "    \n",
    "    for box in results[0].boxes.data.cpu().numpy():\n",
    "        x1, y1, x2, y2, conf, cls_id = box\n",
    "        boxes.append([x1, y1, x2, y2])\n",
    "        cls_ids.append(cls_id)\n",
    "        confs.append(conf)\n",
    "    \n",
    "    # Filter drones only\n",
    "    drone_boxes, _ = filter_drones(boxes, cls_ids, confs, frame.shape)\n",
    "    \n",
    "    # Track\n",
    "    tracks = tracker.update(drone_boxes)\n",
    "    \n",
    "    # Scale frame\n",
    "    frame_out = cv2.resize(frame, (out_w, out_h))\n",
    "    \n",
    "    # Draw\n",
    "    for tid, bbox in tracks:\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        x1_s = int(x1 * scale)\n",
    "        y1_s = int(y1 * scale)\n",
    "        x2_s = int(x2 * scale)\n",
    "        y2_s = int(y2 * scale)\n",
    "        \n",
    "        cv2.rectangle(frame_out, (x1_s, y1_s), (x2_s, y2_s), (0, 255, 0), 2)\n",
    "        cv2.putText(frame_out, f'ID:{tid}', (x1_s, max(15, y1_s-6)), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "        csv_lines.append(f\"{frame_count},{tid},{int(x1)},{int(y1)},{int(x2)},{int(y2)}\")\n",
    "    \n",
    "    out.write(frame_out)\n",
    "    \n",
    "    if frame_count % 100 == 0:\n",
    "        print(f\"Processed {frame_count} frames...\")\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "# Save CSV\n",
    "csv_path = output_path.replace('.mp4', '.csv')\n",
    "with open(csv_path, 'w') as f:\n",
    "    f.write('\\n'.join(csv_lines))\n",
    "\n",
    "print(f\"\\n✓ Done!\")\n",
    "print(f\"Output video: {output_path}\")\n",
    "print(f\"Tracking CSV: {csv_path}\")\n",
    "print(f\"Total frames: {frame_count}\")\n",
    "print(f\"Total drones tracked: {len(set([int(line.split(',')[1]) for line in csv_lines[1:]]))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8125abb",
   "metadata": {},
   "source": [
    "## STEP 6: View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b6d2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and display CSV\n",
    "df = pd.read_csv(csv_path)\n",
    "print(f\"Tracking data shape: {df.shape}\")\n",
    "print(f\"\\nFirst 10 rows:\")\n",
    "print(df.head(10))\n",
    "print(f\"\\nLast 10 rows:\")\n",
    "print(df.tail(10))\n",
    "print(f\"\\nDrone IDs found: {sorted(df['id'].unique())}\")\n",
    "print(f\"Total detections: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0f161f",
   "metadata": {},
   "source": [
    "## VIDEO OUTPUT LOCATION\n",
    "\n",
    "Open with VLC or Windows Media Player:\n",
    "```\n",
    "e:\\kshatra\\drone-tracker\\outputs\\tracked_fast_demo.mp4\n",
    "```\n",
    "\n",
    "You should see:\n",
    "- ✓ Green boxes around drones only\n",
    "- ✓ ID numbers (1, 2, 3, etc.) on each drone\n",
    "- ✓ Boxes follow drones across frames (tracking!)\n",
    "- ✓ Smooth motion (Kalman filter)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7597126",
   "metadata": {},
   "source": [
    "## SUMMARY\n",
    "\n",
    "### The Algorithm Flow\n",
    "```\n",
    "Video Frame\n",
    "    ↓\n",
    "[YOLO] Detects all objects\n",
    "    ↓\n",
    "[Filter] Keep only drones\n",
    "    ↓\n",
    "[Hungarian] Match drones to previous tracks\n",
    "    ↓\n",
    "[Kalman Filter] Smooth motion & predict next position\n",
    "    ↓\n",
    "[Output] Draw boxes, save CSV\n",
    "```\n",
    "\n",
    "### Why ID Numbers?\n",
    "- Track 1 = First drone (appears in frame 50-300)\n",
    "- Track 2 = Second drone (appears in frame 100-250)\n",
    "- Each track has its own ID so you know which drone is which\n",
    "\n",
    "### Why So Much Data in CSV?\n",
    "- One row = one detection in one frame\n",
    "- Video = 30 FPS × 100 seconds = 3000 frames\n",
    "- 1 drone = 3000 rows (one per frame)\n",
    "- This is normal! It tracks every frame\n",
    "\n",
    "### Performance\n",
    "- **CPU**: ~5-10 FPS (slow but works)\n",
    "- **With scale=0.6**: ~15 FPS (3x faster!)\n",
    "- **GPU (CUDA)**: Would be 50+ FPS\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c1bf12",
   "metadata": {},
   "source": [
    "## HOW TO RUN THIS EVERY TIME\n",
    "\n",
    "### Option 1: PowerShell Command (Fastest)\n",
    "```powershell\n",
    "$conda = \"C:\\Users\\chipn\\Miniconda3\\Scripts\\conda.exe\"\n",
    "Set-Location 'e:\\kshatra\\drone-tracker'\n",
    "& $conda run -n drone39 python -m src.main --input-dir videos --output-dir outputs --conf 0.15 --scale 0.6\n",
    "```\n",
    "\n",
    "### Option 2: Run From This Notebook\n",
    "Just re-run cells 5-6 above after adding new videos\n",
    "\n",
    "### Option 3: Double-Click Script (Easiest)\n",
    "I'll create `run_tracker.ps1` - right-click → Run with PowerShell\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcd4c51",
   "metadata": {},
   "source": [
    "## NEXT STEPS\n",
    "\n",
    "1. **Add your videos** to `e:\\kshatra\\drone-tracker\\videos\\`\n",
    "2. **Run the tracker** (any option above)\n",
    "3. **Check outputs** in `e:\\kshatra\\drone-tracker\\outputs\\`\n",
    "4. **Verify tracking** - open MP4 in VLC, see green boxes\n",
    "5. **Analyze data** - open CSV in Excel\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
